# Android-Application-for-Visually-Impaired

** Name : Eashan Adhikarla | Date : October 2016 **

It is a realtime object recognition and classification system for visually impaired, which can be leveraged as an outdoor navigation system with voice commands. In this model, I used K-Nearest Neighbor to classify the images using ILSVRC 2015 dataset which has 1000 object categories containing internal and leaf nodes of ImageNet. Currently, I am modifying it to use Deep Convolutional Nueral Networks so as to improve performance in some domains.

Abstractâ€” Image Recognition and the image classification has been one of the weighing gravitate towards computer vision and has been lagging in certainty. The field of Machine Learning has made a tremendous progress in object detection with a refined quality. With the usage of model like SVM, KNN, Bag of words I have improved the classification precision but still sparring with the amount of accuracy until deep convolutional neural networks came in existence with which I can exceed human performance in some domains. Here I introduced Tensorflow based model which uses deep convolutional network of 22 layers deep network which is trained with dataset of ILSVRC 2015 with a thousand classes to classify the image. I built an android application that can dynamically recognize and classify the images on the screen with an intuition of multi-scale processing.

