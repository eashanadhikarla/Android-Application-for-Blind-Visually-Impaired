# Android-Application-for-Visually-Impaired

**Created By: Eashan Adhikarla | Date: October 2016**

It is a realtime object recognition and classification system for visually impaired, which can be leveraged as an outdoor navigation system with voice commands. In this model, I used K-Nearest Neighbor to classify the images using ILSVRC 2015 dataset which has 1000 object categories containing internal and leaf nodes of ImageNet. Currently, I am modifying it to use Deep Convolutional Nueral Networks so as to improve performance in some domains.

## Abstract: 
Image Recognition and the image classification has been one of the weighing gravitate towards computer vision and has been lagging in certainty. The field of Machine Learning has made a tremendous progress in object detection with a refined quality. With the usage of model like SVM, KNN, Bag of words I have improved the classification precision but still sparring with the amount of accuracy until deep convolutional neural networks came in existence with which I can exceed human performance in some domains. Here I introduced Tensorflow based model which uses deep convolutional network of 22 layers deep network which is trained with dataset of ILSVRC 2015 with a thousand classes to classify the image. I built an android application that can dynamically recognize and classify the images on the screen with an intuition of multi-scale processing.

## Licensing:
Unless otherwise stated, the source code and trained Python model files are copyright and licensed under the [MIT License](https://github.com/eashanadhikarla/Android-Application-for-Visually-Impaired/blob/master/LICENSE). Portions from the following third party sources have been modified and are included in this repository.
